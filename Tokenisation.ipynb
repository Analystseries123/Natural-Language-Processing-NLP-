{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e290dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation:\n",
    "# Tokenization is the process of breaking down a piece of text,like,a sentence or a para."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2b429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\himanshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b3fbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's\", 'play', 'a', 'game,Would', 'you', 'Rather!', \"It's\", 'simple,', 'you', 'have', 'to', 'pick', 'one', 'or', 'the', 'other.', \"Let's\", 'get', 'started.', 'Would', 'you', 'rather', 'try', 'Vanilla', 'Ice', 'cream', 'or', 'Chocolate', 'one?', 'Would', 'you', 'rather', 'be', 'a', 'bird', 'or', 'a', 'bat?', 'Would', 'you', 'rather', 'explore', 'space', 'or', 'the', 'ocean?', 'Would', 'you', 'rather', 'live', 'on', 'Mars', 'or', 'on', 'the', 'Moon?', 'Would', 'you', 'rather', 'have', 'many', 'good', 'friends', 'or', 'one', 'very', 'best', 'friend?', \"Isn't\", 'it', 'easy', 'though?', 'When', 'we', 'have', 'less', \"choices,it's\", 'easier', 'to', 'decide.But', 'Waht', 'if', 'the', 'options', 'Would', 'be', 'complicated?', 'I', 'guess,', 'you', 'pretty', 'much', 'not', 'understand', 'my', 'point,neither', 'did', 'I,', 'at', 'first', 'place', 'and', 'that', 'led', 'me', 'to', 'a', 'Bad', 'Decision.']\n"
     ]
    }
   ],
   "source": [
    "# word Tokenization using the split() function\n",
    "my_text = \"\"\" Let's play a game,Would you Rather! It's simple, you have to pick one or the\n",
    "other. Let's get started. Would you rather try Vanilla Ice cream or Chocolate one? Would you rather be a bird or a bat?\n",
    "Would you rather explore space or the ocean? Would you rather live on Mars or on the Moon?\n",
    "Would you rather have many good friends or one very best friend? Isn't it easy though?\n",
    "When we have less choices,it's easier to decide.But Waht if the options Would be complicated?\n",
    "I guess, you pretty much not understand my point,neither did I, at first place and that led me to a Bad Decision.\"\"\"\n",
    "\n",
    "print(my_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40288966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import(word_tokenize,sent_tokenize,TreebankWordTokenizer,wordpunct_tokenize,TweetTokenizer,MWETokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d20b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'Work hard stay healthy think positive! #Himanshu # Kumar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4da09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Work', 'hard', 'stay', 'healthy', 'think', 'positive', '!', '#', 'Himanshu', '#', 'Kumar']\n"
     ]
    }
   ],
   "source": [
    "# word Tokenizer\n",
    "print(word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ebdbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Work hard stay healthy think positive!', '#Himanshu # Kumar']\n"
     ]
    }
   ],
   "source": [
    "# sentence Tokenizer\n",
    "print(sent_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c31a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello guys.Welcome to AAFT.', 'You are studying NLP -article']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hello guys.Welcome to AAFT. You are studying NLP -article'\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79ff5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'guys',\n",
       " '.',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'AAFT',\n",
       " '.',\n",
       " 'you',\n",
       " 'are',\n",
       " 'studying',\n",
       " 'NLP',\n",
       " '-',\n",
       " 'article']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hello guys. Welcome to AAFT. you are studying NLP - article'\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d707c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Work', 'hard', 'stay', 'healthy', 'think', 'positive', '!', '#', 'Himanshu', '#', 'Kumar']\n"
     ]
    }
   ],
   "source": [
    "# Punctuation-based tokenizer: This tokenizer splits the sentence into words based.\n",
    "print(wordpunct_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a9b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treebank word tokenizer\n",
    "# This tokenizer incorporated a variety of common rules for english word tokenizetion IT separates phrase-terminating punctuation like(?!.;,)\n",
    "# FROM adjacent tokens and retains decimal numbers as a single token. Besides, it contains rules for English contractions.\n",
    "# for example 'don't is tokenize as ['do',:'n't']. you can find all the rules for the Treebank Tokenizer at this link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1941fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'do', 'you', 'do', \"n't\", 'want', 'to', 'done', 'to', 'yourself', ',', 'do', \"n't\", 'do', 'to', 'others', '...']\n"
     ]
    }
   ],
   "source": [
    "txt1 = \"What do you don't want to done to yourself,don't do to others...\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "print(tokenizer.tokenize(txt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0058839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'guys',\n",
       " '.',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'AAFT',\n",
       " '.',\n",
       " 'you',\n",
       " 'are',\n",
       " 'studying',\n",
       " 'NLP',\n",
       " '-',\n",
       " 'article']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello guys.Welcome to AAFT. you are studying NLP-article\"\n",
    "wordpunct_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638403a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
